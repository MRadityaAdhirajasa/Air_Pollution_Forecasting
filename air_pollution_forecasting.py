# -*- coding: utf-8 -*-
"""Air_Pollution_Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1to_LTX2yWlsvR35PQQK9upMuUALn42a4

# Air Pollution Forecasting

## Load Data
"""

from google.colab import files

!kaggle datasets download -d rupakroy/lstm-datasets-multivariate-univariate --unzip -p LSTM-Multivariate_pollution

"""## Library"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import seaborn as sns
from math import sqrt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dropout, Dense, BatchNormalization, GRU
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error as mse
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

"""## Exploratory Data Analysis"""

df_train = pd.read_csv('/content/LSTM-Multivariate_pollution/LSTM-Multivariate_pollution.csv')
df_train

df_train.info()

df_test = pd.read_csv("/content/LSTM-Multivariate_pollution/pollution_test_data1.csv")
df_test

df_test.info()

print("train data\n", df_train.isnull().sum())

print("test data\n", df_test.isnull().sum())

df_train.shape

df_train.describe()

columns_to_plot = [col for col in df_train.columns if col != 'date']

rows = 3
cols = 3

fig, axes = plt.subplots(rows, cols, figsize=(15, 8))
axes = axes.flatten()

for i, col in enumerate(columns_to_plot):
    sns.boxplot(y=df_train[col], ax=axes[i])
    axes[i].set_title(f"Boxplot: {col}", fontsize=12)
    axes[i].set_ylabel("Distribusi", fontsize=10)
    axes[i].set_xlabel("")

for j in range(len(columns_to_plot), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

sns.set(style="darkgrid")

fig, axs = plt.subplots(3,2, figsize=(24,14))

sns.histplot(data=df_test, x="pollution", kde=True, color="skyblue", ax=axs[0, 0])
sns.histplot(data=df_test, x="dew", kde=True, color="olive", ax=axs[0, 1])
sns.histplot(data=df_test, x="temp", kde=True, color="gold", ax=axs[1, 0])
sns.histplot(data=df_test, x="press", kde=True, color="teal", ax=axs[1, 1])
sns.histplot(data=df_test, x="wnd_dir", kde=True, color="steelblue", ax=axs[2, 0])
sns.histplot(data=df_test, x="wnd_spd", kde=True, color="goldenrod", ax=axs[2, 1])

plt.show()

"""## Data Preparation"""

mapping = {'NE': 0, 'SE': 1, 'NW': 2, 'cv': 3}

df_train['wnd_dir'] = df_train['wnd_dir'].map(mapping)
df_test['wnd_dir'] = df_test['wnd_dir'].map(mapping)

df_train['date'] = pd.to_datetime(df_train['date'])

df_train.set_index('date', inplace=True)
df_train.head()

scaler = MinMaxScaler()

columns = (['pollution', 'dew', 'temp', 'press', "wnd_dir", 'wnd_spd',
       'snow', 'rain'])

df_test = df_test[columns]

df_train[columns] = scaler.fit_transform(df_train[columns])
df_test[columns] = scaler.transform(df_test[columns])

df_train.head()

df_test.head()

df_train_scaled = np.array(df_train)
df_test_scaled = np.array(df_test)

X = []
y = []
n_future = 1
n_past = 11

for i in range(n_past, len(df_train_scaled) - n_future+1):
    X.append(df_train_scaled[i - n_past:i, 1:df_train_scaled.shape[1]])
    y.append(df_train_scaled[i + n_future - 1:i + n_future, 0])
X_train, y_train = np.array(X), np.array(y)

X = []
y = []
for i in range(n_past, len(df_test_scaled) - n_future+1):
    X.append(df_test_scaled[i - n_past:i, 1:df_test_scaled.shape[1]])
    y.append(df_test_scaled[i + n_future - 1:i + n_future, 0])
X_test, y_test = np.array(X), np.array(y)

print('train shape : {}, {} \n'
      'test shape : {}, {} '.format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))

"""## LSTM Model"""

model = Sequential()

# Lapisan LSTM pertama
model.add(LSTM(
    units=64,
    input_shape=(X_train.shape[1], X_train.shape[2]),
    return_sequences=True,
))
model.add(Dropout(0.3))

# Lapisan LSTM kedua
model.add(LSTM(
    units=32,
    return_sequences=True
))
model.add(Dropout(0.3))

# Lapisan LSTM ketiga
model.add(LSTM(
    units=16,
    return_sequences=False
))
model.add(Dropout(0.3))

# Lapisan Dense untuk output
model.add(Dense(y_train.shape[1]))

# Compile model
model.compile(
    loss='mse',
    optimizer=Adam(learning_rate=0.001),
    metrics=[RootMeanSquaredError()]
)

model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)

history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping, checkpoint], shuffle=False)

best_model = load_model('best_model.keras')

plt.figure(figsize=(15,6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

test_predictions = best_model.predict(X_test).flatten()
test_results = pd.DataFrame(data={'Train Predictions': test_predictions,
                                  'Actual':y_test.flatten()})
test_results.head()

plt.plot(test_results['Train Predictions'][:200], label='Predicted Values')
plt.plot(test_results['Actual'][:200], label='True Values')
plt.legend()
plt.show()

"""## GRU Model"""

model = Sequential()

# Lapisan GRU pertama
model.add(GRU(
    units=128,
    input_shape=(X_train.shape[1], X_train.shape[2]),
    return_sequences=True,
    kernel_regularizer='l2',
))
model.add(Dropout(0.3))
model.add(BatchNormalization())

# Lapisan GRU kedua
model.add(GRU(
    units=64,
    return_sequences=True
))
model.add(Dropout(0.3))
model.add(BatchNormalization())

# Lapisan GRU ketiga
model.add(GRU(
    units=32,
    return_sequences=False
))
model.add(Dropout(0.3))

# Lapisan Dense tambahan
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(y_train.shape[1]))

model.compile(
    loss='mse',
    optimizer=Adam(learning_rate=0.001),
    metrics=[RootMeanSquaredError()]
)

model.summary()

# Callback untuk menyimpan model terbaik
gru_model_checkpoint = ModelCheckpoint('best_gru_model.keras', monitor='val_loss', save_best_only=True)

history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping, gru_model_checkpoint], shuffle=False)

best_gru_model = load_model('best_gru_model.keras')

plt.figure(figsize=(15,6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

test_predictions_gru = best_gru_model.predict(X_test).flatten()
test_results_gru = pd.DataFrame(data={'Train Predictions': test_predictions,
                                  'Actual':y_test.flatten()})
test_results_gru.head()

plt.plot(test_results_gru['Train Predictions'][:200], label='Predicted Values')
plt.plot(test_results_gru['Actual'][:200], label='True Values')
plt.legend()
plt.show()

"""## Evaluasi"""

gru_train_mse = best_gru_model.evaluate(X_train, y_train, verbose=0)[0]
gru_test_mse = best_gru_model.evaluate(X_test, y_test, verbose=0)[0]

print(f"GRU Train MSE: {gru_train_mse}")
print(f"GRU Test MSE: {gru_test_mse}")

lstm_train_mse = best_model.evaluate(X_train, y_train, verbose=0)[0]
lstm_test_mse = best_model.evaluate(X_test, y_test, verbose=0)[0]

print(f"LSTM Train MSE: {lstm_train_mse}")
print(f"LSTM Test MSE: {lstm_test_mse}")

gru_train_rmse = best_gru_model.evaluate(X_train, y_train, verbose=0)[1]
gru_test_rmse = best_gru_model.evaluate(X_test, y_test, verbose=0)[1]

print(f"GRU Train RMSE: {gru_train_rmse}")
print(f"GRU Test RMSE: {gru_test_rmse}")

lstm_train_rmse = best_model.evaluate(X_train, y_train, verbose=0)[1]
lstm_test_rmse = best_model.evaluate(X_test, y_test, verbose=0)[1]

print(f"LSTM Train RMSE: {lstm_train_rmse}")
print(f"LSTM Test RMSE: {lstm_test_rmse}")